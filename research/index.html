<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Research | Colin Kohler</title>
<meta name="description" content="test description">


  <meta name="author" content="Colin Kohler">
  


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Colin Kohler">
<meta property="og:title" content="Research">
<meta property="og:url" content="https://colinkohler.github.io/webpage/research/">


  <meta property="og:description" content="test description">



  <meta property="og:image" content="https://colinkohler.github.io/webpage/site-logo.png">









  

  


<link rel="canonical" href="https://colinkohler.github.io/webpage/research/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Colin Kohler",
      "url": "https://colinkohler.github.io/webpage/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/webpage/feed.xml" type="application/atom+xml" rel="alternate" title="Colin Kohler Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/webpage/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--collection wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/webpage/">
          Colin Kohler
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/webpage/research/">Research</a>
            </li><li class="masthead__menu-item">
              <a href="/webpage/code/">Code</a>
            </li><li class="masthead__menu-item">
              <a href="/webpage/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/webpage/cv/">CV</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/webpage/assets/images/avatar.jpg" alt="Colin Kohler" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Colin Kohler</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>I am a stick.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Boston, MA</span>
        </li>
      

      
        
          
            <li><a href="mailto:colink78@gmail.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
            <li><a href="https://github.com/ColinKohler" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">Github</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/colin-kohler-217922109/" rel="nofollow noopener noreferrer"><i class="gab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://scholar.google.com/citations?hl=en&user=QuFhQt0AAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i><span class="label">Scholar</span></a></li>
          
        
          
            <li><a href="https://www.instagram.com/just_one_peanut_butter_square/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i><span class="label">Instrgram</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <div class="archive">
    
      <h1 id="page-title" class="page__title">Research</h1>
    
    <p>A complete list of plublications can be found at <a href="https://scholar.google.com/citations?hl=en&amp;user=QuFhQt0AAAAJ">Google Scholar</a>.</p>

<hr />

<h2> Visual Foresight with a Local Dynamics Model (2022) </h2>
<p>Colin Kohler, Robert Platt — ISRR 2022</p>
<p float="left">
    <button type="button" class="btn btn-primary active"> 
    <a href="https://arxiv.org/pdf/2206.14802.pdf" style="color:inherit">PDF</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="https://github.com/ColinKohler/LocalDynamicsModel" style="color:inherit">Code</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="" style="color:inherit">Website</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:qrJqMCKbz2oJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgXlfr8lEIi0gmszfrQ:AAGBfm0AAAAAYuA1ZrQw0Mr7iZ1YBkfz1c1yOIq9k25W&amp;scisig=AAGBfm0AAAAAYuA1Zquo_VNaxD9KXexF-CDVEq-paj0f&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en" style="color:inherit">Cite</a>
</button>

  </p>
<p><strong>Abstract:</strong> Model-free policy learning has been shown to be capable of learning manipulation policies which can solve long-time horizon tasks using single-step manipulation primitives. However, training these policies is a time-consuming process requiring large amounts of data. We propose the Local Dynamics Model (LDM) which efficiently learns the state-transition function for these manipulation primitives. By combining the LDM with model-free policy learning, we can learn policies which can solve complex manipulation tasks using one-step lookahead planning. We show that the LDM is both more sample-efficient and outperforms other model architectures. When combined with planning, we can outperform other model-based and model-free policies on several challenging manipulation tasks in simulation.</p>

<hr />

<h2> BulletArm: An Open-Source Robotic Manipulation Benchmark and Learning Framework (2022) </h2>
<p>Dian Wang*, Colin Kohler*, Xupeng Zhu, Mingxi Jia, Robert Platt — ISRR 2022</p>
<p float="left">
    <button type="button" class="btn btn-primary active"> 
    <a href="https://arxiv.org/pdf/2205.14292.pdf" style="color:inherit">PDF</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="https://github.com/ColinKohler/BulletArm" style="color:inherit">Code</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="https://colinkohler.github.io/BulletArm/" style="color:inherit">Website</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:uSazIfEssOgJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgXlfr8lEIi0gmswxwY:AAGBfm0AAAAAYuA23wZsfvj4mzTkS2F_BS0kMvzFJRLX&amp;scisig=AAGBfm0AAAAAYuA23yS9HCo5UrpfQcf8iMOclLZTvi9E&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en" style="color:inherit">Cite</a>
</button>

  </p>
<p><strong>Abstract:</strong> We present BulletArm, a novel benchmark and learning-environment for robotic manipulation. BulletArm is designed around two key principles: reproducibility and extensibility. We aim to encourage more direct comparisons between robotic learning methods by providing a set of standardized benchmark tasks in simulation alongside a collection of baseline algorithms. The framework consists of 31 different manipulation tasks of varying difficulty, ranging from simple reaching and picking tasks to more realistic tasks such as bin packing and pallet stacking. In addition to the provided tasks, BulletArm has been built to facilitate easy expansion and provides a suite of tools to assist users when adding new tasks to the framework. Moreover, we introduce a set of five benchmarks and evaluate them using a series of state-of-the-art baseline algorithms. By including these algorithms as part of our framework, we hope to encourage users to benchmark their work on any new tasks against these baselines.</p>

<hr />

<h2> Policy learning in SE(3) action spaces (2020) </h2>
<p>Dian Wang, Colin Kohler, Robert Platt — CoRL 2020</p>
<p float="left">
    <button type="button" class="btn btn-primary active"> 
    <a href="https://arxiv.org/pdf/2010.02798.pdf" style="color:inherit">PDF</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="https://github.com/pointW/asrse3_corl20" style="color:inherit">Code</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="https://pointw.github.io/asrse3-page/" style="color:inherit">Website</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:1e3aTS2SmjAJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgXlfr8lEIi0gms-G80:AAGBfm0AAAAAYuA4A80lA9Vu0rRoWmIYNDk_vrcSJM7M&amp;scisig=AAGBfm0AAAAAYuA4A4RjqaJsqeyeACcYcFUjNYhM4e9g&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en" style="color:inherit">Cite</a>
</button>

  </p>
<p><strong>Abstract:</strong> In the spatial action representation, the action space spans the space of target poses for robot motion commands, i.e. SE(2) or SE(3). This approach has been used to solve challenging robotic manipulation problems and shows promise. However, the method is often limited to a three dimensional action space and short horizon tasks. This paper proposes ASRSE3, a new method for handling higher dimensional spatial action spaces that transforms an original MDP with high dimensional action space into a new MDP with reduced action space and augmented state space. We also propose SDQfD, a variation of DQfD designed for large action spaces. ASRSE3 and SDQfD are evaluated in the context of a set of challenging block construction tasks. We show that both methods outperform standard baselines and can be used in practice on real robotics systems.</p>

<hr />

<h2> Towards Assistive Robotic Pick and Place in Open World Environments (2019) </h2>
<p>Dian Wang, Colin Kohler, Andreas ten Pas, Alexander Wilkinson, Maozhi Lui, Holly Yanco, Robert Platt — ISRR 2019</p>
<p float="left">
    <button type="button" class="btn btn-primary active"> 
    <a href="https://arxiv.org/pdf/1809.09541.pdf" style="color:inherit">PDF</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="" style="color:inherit">Code</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="https://pointw.github.io/scooter-page/" style="color:inherit">Website</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:nAoc436qQscJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgXlfr8lEIi0gms_KU0:AAGBfm0AAAAAYuA5MU1_fpvdUGbN5CITp57uM5mKNxRO&amp;scisig=AAGBfm0AAAAAYuA5MWsVwLeaf4LKoF0P_tyw9a5eWUpz&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en" style="color:inherit">Cite</a>
</button>

  </p>
<p><strong>Abstract:</strong> Assistive robot manipulators must be able to autonomously pick and place a wide range of novel objects to be truly useful. However, current assistive robots lack this capability. Additionally, assistive systems need to have an interface that is easy to learn, to use, and to understand. This paper takes a step forward in this direction. We present a robot system comprised of a robotic arm and a mobility scooter that provides both pick-and-drop and pick-and-place functionality for open world environments without modeling the objects or environment. The system uses a laser pointer to directly select an object in the world, with feedback to the user via projecting an interface into the world. Our evaluation over several experimental scenarios shows a significant improvement in both runtime and grasp success rate relative to a baseline from the literature, and furthermore demonstrates accurate pick and place capabilities for tabletop scenarios.</p>

<hr />

<h2> Deictic Image Maps: An Abstraction For Learning Pose Invariant Manipulation Policies (2019) </h2>
<p>Robert Platt, Colin Kohler, Marcus Gualtieri — AAAI 2019</p>
<p float="left">
    <button type="button" class="btn btn-primary active"> 
    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/4806/4684" style="color:inherit">PDF</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="" style="color:inherit">Code</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="" style="color:inherit">Website</a>
</button>

    <button type="button" class="btn btn-primary active"> 
    <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:em1sR7zo7O8J:scholar.google.com/&amp;output=citation&amp;scisdr=CgXlfr8lEIi0gms_-EM:AAGBfm0AAAAAYuA54EO-BoPI__eAiuQ3fxfo6G3usi9e&amp;scisig=AAGBfm0AAAAAYuA54OSYmCXyw08SJAn8vRdmB_-Qrmng&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en" style="color:inherit">Cite</a>
</button>

  </p>
<p><strong>Abstract:</strong> In applications of deep reinforcement learning to robotics, it is often the case that we want to learn pose invariant policies: policies that are invariant to changes in the position and orientation of objects in the world. For example, consider a peg-in-hole insertion task. If the agent learns to insert a peg into one hole, we would like that policy to generalize to holes presented in different poses. Unfortunately, this is a challenge using conventional methods. This paper proposes a novel state and action abstraction that is invariant to pose shifts called <em>deictic image maps</em> that can be used with deep reinforcement learning. We provide broad conditions under which optimal abstract policies are optimal for the underlying system. Finally, we show that the method can help solve challenging robotic manipulation problems.</p>

<hr />




<div class="entries-list">
  




</div>

  </div>
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    
      <li><a href="/webpage/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Colin Kohler. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/webpage/assets/js/main.min.js"></script>




<script src="/webpage/assets/js/lunr/lunr.min.js"></script>
<script src="/webpage/assets/js/lunr/lunr-store.js"></script>
<script src="/webpage/assets/js/lunr/lunr-en.js"></script>







  </body>
</html>
